{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ratulb/pytorch/blob/main/mnist_in_pythor_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def w_sum(a,b):\n",
        " assert(len(a) == len(b))\n",
        " output = 0\n",
        " for i in range(len(a)):\n",
        "    output += (a[i] * b[i])\n",
        " return output\n",
        "\n",
        "weights = [0.1, 0.2, 0]\n",
        "\n",
        "def neural_network(input, weights):\n",
        " pred = w_sum(input,weights)\n",
        " return pred\n",
        "\n",
        "toes = [8.5, 9.5, 9.9, 9.0]\n",
        "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
        "nfans = [1.2, 1.3, 0.5, 1.0]\n",
        "\n",
        "input = [toes[0],wlrec[0],nfans[0]]\n",
        "\n",
        "pred = neural_network(input,weights)\n",
        "\n",
        "print(pred)"
      ],
      "metadata": {
        "id": "_FqNHF73gBWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "weights = np.array([0.1, 0.2, 0])\n",
        "def neural_network(input, weights):\n",
        " pred = input.dot(weights)\n",
        " return pred\n",
        "toes = np.array([8.5, 9.5, 9.9, 9.0])\n",
        "wlrec = np.array([0.65, 0.8, 0.8, 0.9])\n",
        "nfans = np.array([1.2, 1.3, 0.5, 1.0])\n",
        "input = np.array([toes[0],wlrec[0],nfans[0]])\n",
        "pred = neural_network(input,weights)\n",
        "print(pred)"
      ],
      "metadata": {
        "id": "o7-yyMP7huZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# toes % win # fans\n",
        "ih_wgt = np.array([\n",
        " [0.1, 0.2, -0.1],\n",
        " [-0.1,0.1, 0.9],\n",
        " [0.1, 0.4, 0.1]]).T\n",
        "\n",
        "print(ih_wgt.shape)\n",
        "\n",
        "hp_wgt = np.array([\n",
        " [0.3, 1.1, -0.3],\n",
        " [0.1, 0.2, 0.0],\n",
        " [0.0, 1.3, 0.1] ]).T\n",
        "\n",
        "weights = [ih_wgt, hp_wgt]\n",
        "\n",
        "\n",
        "def neural_network(input, weights):\n",
        " hid = input.dot(weights[0])\n",
        " pred = hid.dot(weights[1])\n",
        " return pred\n",
        "\n",
        "toes = np.array([8.5, 9.5, 9.9, 9.0])\n",
        "wlrec = np.array([0.65,0.8, 0.8, 0.9])\n",
        "nfans = np.array([1.2, 1.3, 0.5, 1.0])\n",
        "\n",
        "\n",
        "input = np.array([toes[0],wlrec[0],nfans[0]])\n",
        "pred = neural_network(input,weights)\n",
        "print(pred)\n",
        "\n",
        "hid1 = [8.5 * 0.1 +0.65 * 0.2 +  1.2 * (-0.1), 8.5 * (-0.1) +0.65 * 0.1 +  1.2 * 0.9, 8.5 * 0.1 +0.65 * 0.4 +  1.2 * 0.1]\n",
        "hid2 = [hid1[0] * 0.3 + hid1[1] * 1.1 -  hid1[2]*0.3 , hid1[0] * 0.1 + hid1[1] * 0.2 ,  hid1[1] * 1.3 +  hid1[2] * 0.1]\n",
        "print(hid2)"
      ],
      "metadata": {
        "id": "fs6FVlPujsg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight = 0.5\n",
        "input = 0.5\n",
        "goal_prediction = 0.8\n",
        "step_amount = 0.001\n",
        "for iteration in range(1101):\n",
        " prediction = input * weight\n",
        " error = (prediction - goal_prediction) ** 2\n",
        " print(\"Error:\" + str(error) + \" Prediction:\" + str(prediction))\n",
        "\n",
        " up_prediction = input * (weight + step_amount)\n",
        " up_error = (goal_prediction - up_prediction) ** 2\n",
        " down_prediction = input * (weight - step_amount)\n",
        " down_error = (goal_prediction - down_prediction) ** 2\n",
        " if(down_error < up_error):\n",
        "    weight = weight - step_amount\n",
        "\n",
        " if(down_error > up_error):\n",
        "    weight = weight + step_amount"
      ],
      "metadata": {
        "id": "7MunRFT3vAvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight = -0.5\n",
        "goal_pred = 0.8\n",
        "input = -0.5\n",
        "for iteration in range(100):\n",
        " pred = input * weight\n",
        " error = (pred - goal_pred) ** 2\n",
        " direction_and_amount = (pred - goal_pred) * input\n",
        " weight = weight - direction_and_amount\n",
        " print(\"Error:\" + str(error) + \" Prediction:\" + str(pred))"
      ],
      "metadata": {
        "id": "6r1-LGRoMZoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = [[1,1,1], [2,2,2], [3,31,3], [4,41,4]]\n",
        "result = [row[1] for row in m[2:]]\n",
        "print(result)"
      ],
      "metadata": {
        "id": "T4zpV2Hi4iff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "m = np.array([[1, 1, 1], [2, 2, 2], [3, 31, 3], [4, 41, 4]])\n",
        "\n",
        "# Slicing the 3rd row onwards and selecting the 2nd column\n",
        "result = m[2:, 1]\n",
        "class MyClass:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "    def __str__(self):\n",
        "        return self.name\n",
        "\n"
      ],
      "metadata": {
        "id": "Ec-fTeH06OsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ykBhZIxN6Oq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Original tensor\n",
        "t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "print(\"Original tensor:\")\n",
        "print(t)\n",
        "print(\"Shape:\", t.shape)\n",
        "print(\"Stride:\", t.stride())\n",
        "\n",
        "# Transposed tensor\n",
        "t_transposed = t.t()\n",
        "print(\"\\nTransposed tensor:\")\n",
        "print(t_transposed)\n",
        "print(\"Shape:\", t_transposed.shape)\n",
        "print(\"Stride:\", t_transposed.stride())\n",
        "\n"
      ],
      "metadata": {
        "id": "GwmJzOB9RIoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tuj9C3UZ5ezp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([[1, 2, 3],\n",
        "                  [4, 5, 6],\n",
        "                  [7, 8, 9]])\n",
        "id(t.storage()) == id(t.t().storage())"
      ],
      "metadata": {
        "id": "ODmkP_mzJsii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "t= torch.tensor([[1, 2],\n",
        "        [3, 4],\n",
        "        [5, 6]])\n",
        "t_t = t.t()\n",
        "\n",
        "print(t)\n",
        "print(t_t)\n",
        "print(t.stride())\n",
        "print(t_t.stride())\n",
        "\n",
        "store = t_t.storage()\n",
        "cloned = t_t.clone()\n",
        "print(\"cloned: \", cloned)\n",
        "store[1] = 100\n",
        "print(t)\n",
        "print(t_t)\n",
        "print(\"cloned: \", cloned)"
      ],
      "metadata": {
        "id": "RVLYmmD0LKAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num = 1\n",
        "blocks = []\n",
        "for i in range(1, 4):\n",
        "    block = []\n",
        "    for j in range(1, 5):\n",
        "        row = []\n",
        "        for k in range(1, 6):\n",
        "            row.append(num)\n",
        "            num = num + 1\n",
        "        block.append(row)\n",
        "    blocks.append(block)\n",
        "print(blocks)\n",
        "\n",
        "[for k in range(1, 6)]\n"
      ],
      "metadata": {
        "id": "98QApKUUvV_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "some_tensor = torch.ones(3, 4, 5)\n",
        "some_tensor_t = some_tensor.transpose(0, 2)\n"
      ],
      "metadata": {
        "id": "XmvLyOViz4Yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "blocks = torch.from_numpy(np.arange(1, 61).reshape(3, 4, 5))\n",
        "#torch.save(blocks, \"blocks.t\")\n",
        "#blocks = torch.load(\"blocks.t\")\n",
        "with open(\"blocks.t\", \"wb\") as f:\n",
        "    torch.save(blocks,f)\n",
        "with open(\"blocks.t\", \"rb\") as f:\n",
        "    blocks1 = torch.load(f)\n",
        "print(blocks1.stride())\n",
        "blocks_t1 = blocks.transpose(0, 2)\n",
        "print(blocks_t1.stride())\n",
        "cloned1 = blocks_t1.clone().contiguous()\n",
        "print(cloned1.stride())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7_ILEgC67dts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "points = torch.randn(10, 2)\n",
        "print(points)\n",
        "short_points = points.type(torch.int8)\n",
        "print(short_points)"
      ],
      "metadata": {
        "id": "tkQ7oml8N9rY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import h5py\n",
        "blocks = torch.from_numpy(np.arange(1, 61).reshape(3, 4, 5)).tolist()\n",
        "with h5py.File(\"blocks.h5\", \"w\") as f:\n",
        "    dset = f.create_dataset(\"blocks\", data=blocks)"
      ],
      "metadata": {
        "id": "HLEnKnXiUJMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = h5py.File(\"blocks.h5\", \"r\")\n",
        "loaded_blocks = f[\"blocks\"][:]\n",
        "print(loaded_blocks)\n",
        "f.close()\n",
        "loaded_blocks1 = torch.from_numpy(loaded_blocks).to(device=\"cpu\", dtype=torch.uint8)\n",
        "print(loaded_blocks1.dtype)\n",
        "print(loaded_blocks1.device)\n",
        "loaded_blocks2 = loaded_blocks1.cpu()\n",
        "print(loaded_blocks2.dtype)\n",
        "print(loaded_blocks2.device)"
      ],
      "metadata": {
        "id": "jIlnibuqVEXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(3, 2)\n",
        "print(a)\n",
        "a.zero_()\n",
        "print(a)\n"
      ],
      "metadata": {
        "id": "cc9utEora3k-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_t = torch.from_numpy(np.array(list(range(9))))\n",
        "#print(my_t.size())\n",
        "print(my_t.stride())\n",
        "print(my_t.storage_offset())\n",
        "b = my_t.view(3, 3)\n",
        "print(b.stride())\n",
        "\n",
        "c = b[1:,1:]\n",
        "print(c.stride())\n",
        "cosine= torch.cos(my_t)\n",
        "print(cosine)\n",
        "cosine.zero_()\n",
        "print(cosine)"
      ],
      "metadata": {
        "id": "fHekk61Rccg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/deep-learning-with-pytorch/dlwpt-code/master/data/p1ch4/tabular-wine/winequality-white.csv\"\n",
        "!curl -O $url"
      ],
      "metadata": {
        "id": "06DwuFVpu6aH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n"
      ],
      "metadata": {
        "id": "oMIPzIDjvMXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wine_path=\"/content/winequality-white.csv\"\n",
        "\n",
        "wineq_data = np.loadtxt(wine_path, dtype=np.float32, delimiter=\";\", skiprows=1)\n",
        "columns = next(csv.reader(open(wine_path), delimiter=\";\"))\n",
        "wineq_data.shape, columns\n",
        "wineq = torch.from_numpy(wineq_data)\n",
        "wineq.shape, wineq.type()"
      ],
      "metadata": {
        "id": "WXrjfuMKvQ8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = wineq[:, :-1]\n",
        "data, data.shape\n"
      ],
      "metadata": {
        "id": "GXy1WWTw4QFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = wineq[:, -1]\n",
        "target, target.shape"
      ],
      "metadata": {
        "id": "ZWqBKHIC4x2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_onehot = torch.zeros(target.shape[0], 10)\n"
      ],
      "metadata": {
        "id": "LcsQqgsC86j7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Example target tensor with class indices\n",
        "targets = torch.tensor([0, 1, 2])\n",
        "\n",
        "# Example model output (logits) with 3 classes\n",
        "outputs = torch.randn(3, 3, requires_grad=True)\n",
        "\n",
        "# CrossEntropyLoss expects the targets to be class indices\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "loss = loss_fn(outputs, targets)\n",
        "print(loss)\n"
      ],
      "metadata": {
        "id": "ib3d7_KlAUTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Example target tensor with class indices\n",
        "targets = torch.tensor([0, 1, 2])\n",
        "\n",
        "# One-hot encode the targets\n",
        "one_hot_targets = F.one_hot(targets, num_classes=3).float()\n",
        "\n",
        "print(one_hot_targets)\n"
      ],
      "metadata": {
        "id": "QRn1hiXHAu7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [1.0, 2.3, 5.1, 1.1]\n",
        "weights = [[1.0, 2.0, 3.9, 0.1], [1.0, 1.0, 2.7, -1.0], [1.2, 2.0, 2.1, 0.9]]\n",
        "biases = [2.0, 3.0, 4.0]\n",
        "\n",
        "layer_output = []\n",
        "weights_and_biases = zip(weights, biases)\n",
        "for nueron_weights, neuron_bias in weights_and_biases:\n",
        "    neuron_output = 0\n",
        "    for n_inputs, n_weights in zip(inputs, nueron_weights):\n",
        "        neuron_output += n_inputs * n_weights\n",
        "        print(f\"n_inputs: {n_inputs}, n_weights: {n_weights}\")\n",
        "    neuron_output += neuron_bias\n",
        "    layer_output.append(neuron_output)\n",
        "print(layer_output)\n",
        "\n"
      ],
      "metadata": {
        "id": "KVwF8LbCQw7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in zip([1,2,3],[4,5,6]):\n",
        "    print(x,y)"
      ],
      "metadata": {
        "id": "emjrSn8SWdCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = np.ones((2,1))\n",
        "print(h)\n",
        "i = np.ones((1,2))\n",
        "print(i)\n",
        "j = h.dot(i)\n",
        "\n",
        "print()\n",
        "print(j)\n",
        "print(j.shape)\n"
      ],
      "metadata": {
        "id": "_SS0ogUtWdBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9],\n",
        "    [10, 11, 12],\n",
        "    [13, 14, 15]\n",
        "])\n",
        "bias = 1.0\n",
        "\n",
        "# Weights and bias\n",
        "a = np.array([0.5, -0.2, 0.1])\n",
        "y_pred = np.dot(X, a) + bias\n",
        "\n",
        "# Compute the MSE\n",
        "mse = np.mean((y - y_pred) ** 2)\n",
        "\n",
        "print(\"MSE:\", mse)"
      ],
      "metadata": {
        "id": "V-drnu-qqaw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight = 0.5\n",
        "goal_pred = 100\n",
        "input = 2\n",
        "alpha = 0.1\n",
        "for iteration in range(20):\n",
        " pred = input * weight\n",
        " error = (pred - goal_pred) ** 2\n",
        " derivative = input * (goal_pred - pred)\n",
        " weight = weight + (alpha * derivative)\n",
        "\n",
        " print(\"Error:\" + str(error) + \" Prediction:\" + str(pred))"
      ],
      "metadata": {
        "id": "Qd7UWJ2BzDqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models"
      ],
      "metadata": {
        "id": "QEQAbkHJHb1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet = models.alexnet(pretrained=True)\n"
      ],
      "metadata": {
        "id": "IR8PszAmHjjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary\n"
      ],
      "metadata": {
        "id": "q0jrYl60Mrb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchsummary\n",
        "torchsummary.summary(alexnet, (3, 224, 224))"
      ],
      "metadata": {
        "id": "cno8UhDmM9s6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet = models.resnet101(pretrained=True)\n",
        "#torchsummary.summary(resnet, (3, 224, 224))\n",
        "#resnet"
      ],
      "metadata": {
        "id": "KgWQ2rsNQcch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "img = Image.open(\"/content/dog.png\")\n",
        "print(type(img))\n",
        "image_arr = torch.from_numpy(np.array(img))\n",
        "print(image_arr.shape)\n",
        "img"
      ],
      "metadata": {
        "id": "sP8DmN44T-ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import v2"
      ],
      "metadata": {
        "id": "i5vvwMzMWIk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = v2.Compose([\n",
        "    v2.ToImage(),\n",
        "    v2.Resize(size=(256,), antialias=True),\n",
        "    v2.CenterCrop(224),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "5hkSwpvehYJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_t = transforms(img)\n",
        "print(img_t.shape)"
      ],
      "metadata": {
        "id": "Yk9LQ_kRj1_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "4JR1_6FkkvVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_tensor = img_t.permute(1, 2, 0)\n",
        "\n",
        "# Convert the tensor to a NumPy array\n",
        "image_array = image_tensor.numpy()\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image_array)\n",
        "plt.axis('off')  # Hide axes for better visualization\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sSlvWMQ3k2rF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_t = torch.unsqueeze(img_t, 0)\n",
        "resnet.eval()\n"
      ],
      "metadata": {
        "id": "WaRyhZo3mQzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = resnet(batch_t)\n",
        "output.shape"
      ],
      "metadata": {
        "id": "WkNryCoKnk5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]"
      ],
      "metadata": {
        "id": "J67aFqhapXGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score, index = torch.max(output, 1)\n",
        "print(classes[index[0]], score, index)"
      ],
      "metadata": {
        "id": "GsNKzOOZp4U9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "percentage = torch.nn.functional.softmax(output, dim=1)[0]\n",
        "percentage = (percentage /percentage.sum().item())\n",
        "sum = percentage.sum()\n",
        "print(sum.item())\n",
        "classes[index[0]], percentage[index[0]].item()"
      ],
      "metadata": {
        "id": "nBRQ0F1DqZOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yX90EmRF0E1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet = models.resnet101(pretrained=True)\n",
        "resnet.eval()\n",
        "\n",
        "img = Image.open(\"/content/dog.png\")\n",
        "#img = Image.open(\"/content/800px-A-Cat.jpg\")\n",
        "transforms = v2.Compose([\n",
        "    v2.ToImage(),\n",
        "    v2.Resize(size=(256,), antialias=True),\n",
        "    v2.CenterCrop(224),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "img_t = transforms(img)\n",
        "batch_t = torch.unsqueeze(img_t, 0)\n",
        "output = resnet(batch_t)\n",
        "\n",
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "score, index = torch.max(output, 1)\n",
        "print(classes[index[0]], score, index)\n",
        "\n",
        "percentage = torch.nn.functional.softmax(output, dim=1)[0] * 100\n",
        "\n",
        "classes[index[0]], percentage[index[0]].item()"
      ],
      "metadata": {
        "id": "rEhmzxWa0FKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet = models.resnet101(pretrained=True)\n",
        "resnet.eval()\n",
        "\n",
        "img = Image.open(\"/content/dog.png\")\n",
        "#img = Image.open(\"/content/800px-A-Cat.jpg\")\n",
        "transforms = v2.Compose([\n",
        "    v2.ToImage(),\n",
        "    v2.Resize(size=(256,), antialias=True),\n",
        "    v2.CenterCrop(224),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "img_t = transforms(img)\n",
        "batch_t = torch.unsqueeze(img_t, 0)\n",
        "output = resnet(batch_t)\n",
        "\n",
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "score, index = torch.max(output, 1)\n",
        "print(classes[index[0]], score, index)\n",
        "\n",
        "percentage = torch.nn.functional.softmax(output, dim=1)[0] * 100\n",
        "\n",
        "classes[index[0]], percentage[index[0]].item()\n"
      ],
      "metadata": {
        "id": "96Je81mX2L22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, indices = torch.sort(output, descending=True)\n",
        "[(classes[idx], percentage[idx].item()) for idx in indices[0][:5]]"
      ],
      "metadata": {
        "id": "QpxuJhy_2xfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "import torch\n",
        "resnet = models.resnet18(pretrained=True)\n",
        "resnet.eval()\n",
        "\n",
        "#img = Image.open(\"/content/dog.png\")\n",
        "img = Image.open(\"/content/800px-A-Cat.jpg\")\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "transforms.Resize(256),\n",
        "transforms.CenterCrop(224),\n",
        "transforms.ToTensor(),\n",
        "transforms.Normalize(\n",
        "mean=[0.485, 0.456, 0.406],\n",
        "std=[0.229, 0.224, 0.225]\n",
        ")])\n",
        "img_t = preprocess(img)\n",
        "batch_t = torch.unsqueeze(img_t, 0)\n",
        "output = resnet(batch_t)\n",
        "\n",
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "score, index = torch.max(output, 1)\n",
        "print(classes[index[0]], score, index)\n",
        "\n",
        "percentage = torch.nn.functional.softmax(output, dim=1)[0] * 100\n",
        "\n",
        "classes[index[0]], percentage[index[0]].item()\n",
        "\n"
      ],
      "metadata": {
        "id": "S8FlVP3T4LNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight = 0.5\n",
        "input = 0.5\n",
        "target = 0.8\n",
        "step_size = 0.01\n",
        "for iteration in range(1101):\n",
        " output = input * weight\n",
        " error = (output - target) ** 2\n",
        " print(\"Error:\" + str(error) + \" Prediction:\" + str(output))\n",
        "\n",
        " up_output = input * (weight + step_size)\n",
        " up_error = (target - up_output) ** 2\n",
        " down_output = input * (weight - step_size)\n",
        " down_error = (target - down_output) ** 2\n",
        " if(down_error < up_error):\n",
        "    weight = weight - step_size\n",
        "\n",
        " if(down_error > up_error):\n",
        "    weight = weight + step_size\n"
      ],
      "metadata": {
        "id": "Uwy57Ujxcofx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = [0.5, 1.2, -0.1]\n",
        "targets = [90, 10, -30]\n",
        "inputs = [2.5, 0.5, 1.2]\n",
        "\n",
        "learning_rate = 0.01\n",
        "num_epochs = 100\n",
        "changing_weights = []\n",
        "errors = []\n",
        "for iteration in range(num_epochs):\n",
        "    total_error = 0\n",
        "\n",
        "    # Initialize weight deltas to zero\n",
        "    weight_deltas = [0, 0, 0]\n",
        "\n",
        "    for target in targets:\n",
        "        pred = 0\n",
        "        for input, weight in zip(inputs, weights):\n",
        "            pred += input * weight\n",
        "        error_margin = pred - target\n",
        "        error = (pred - target) ** 2\n",
        "        total_error += error\n",
        "        errors.append(error)\n",
        "\n",
        "        for i in range(len(weights)):\n",
        "            weight_deltas[i] += inputs[i] * error_margin * learning_rate\n",
        "\n",
        "    weights = [x - y for x, y in zip(weights, weight_deltas)]\n",
        "    print(\"Total Error:\" + str(total_error) + \" Prediction:\" + str(pred))\n",
        "\n",
        "    weight_deltas = [x * error_margin * learning_rate for x in inputs]\n",
        "\n",
        "    weights = [x - y for x, y in zip(weights, weight_deltas)]\n",
        "    changing_weights.append(weights)\n",
        "    print(\"Error:\" + str(error) + \" Prediction:\" + str(pred))"
      ],
      "metadata": {
        "id": "D5KPAhe759Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot([x for x in range(num_epochs)], [x[0] for x in changing_weights ], label=\"weight0\")\n",
        "plt.plot([x for x in range(num_epochs)], [x[1] for x in changing_weights ], label=\"weight1\")\n",
        "plt.plot([x for x in range(num_epochs)], [x[2] for x in changing_weights ], label=\"weight2\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"changing_weights\")\n",
        "plt.title('Multiple Graphs in the Same Plot')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1LCJxlYJW_mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights, inputs"
      ],
      "metadata": {
        "id": "GYodP1wjYraS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = [x* y for x, y in zip(inputs, weights)]\n",
        "sum(result)"
      ],
      "metadata": {
        "id": "IxYWyAOKafa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_predictions = []\n",
        "for target in targets:\n",
        "    pred = 0\n",
        "    for input, weight in zip(inputs, weights):\n",
        "        pred += input * weight\n",
        "    final_predictions.append(pred)\n",
        "\n",
        "print(\"Final Predictions based on tuned weights and inputs:\", final_predictions)\n"
      ],
      "metadata": {
        "id": "kJDG32RP7lOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot([x[0] for x in changing_weights ], errors[:100], label=\"weight0\")\n",
        "plt.plot([x[1] for x in changing_weights ], errors[100:200], label=\"weight1\")\n",
        "plt.plot([x[2] for x in changing_weights ], errors[200:300], label=\"weight2\")\n",
        "plt.xlabel(\"Weights\")\n",
        "plt.ylabel(\"Errors\")\n",
        "plt.title('Multiple Graphs in the Same Plot')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VPvywcJk7uyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "4w6AKiW4F4t9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(142)\n",
        "weights = [random.random() for x in range(9)]\n",
        "weights = [[x * 10 for x in weights[:3]], [x * 10 for x in weights[3:6]], [x * 10 for x in weights[6:]]]\n",
        "inputs = [1.2 , -2.6, 0.3]\n",
        "targets = [-5, 7, 25]\n",
        "learning_rate = 0.01\n",
        "num_epochs = 100\n",
        "\n",
        "def network(inputs, weights):\n",
        "    preds = [0, 0, 0]\n",
        "    neuron = 0\n",
        "    for neuron_weights in weights:\n",
        "        for i in range(len(inputs)):\n",
        "            preds[neuron] += neuron_weights[i] * inputs[i]\n",
        "        neuron += 1\n",
        "    return preds\n",
        "\n",
        "\n",
        "def errors(preds, targets, progress):\n",
        "    errors = []\n",
        "    for pred, target in zip(preds, targets):\n",
        "        raw_error = (pred - target)\n",
        "        error = raw_error ** 2\n",
        "        errors.append((error,raw_error))\n",
        "        if target not in progress:\n",
        "            progress[target] = []\n",
        "        progress[target].append(error)\n",
        "        #print(\"Error:\" + str(error) + \" target:\" + str(target))\n",
        "        print(progress[targets[0]][-1])\n",
        "    return errors\n",
        "\n",
        "def weight_deltas(errors, inputs):\n",
        "    weight_deltas = []\n",
        "    for error in errors:\n",
        "        weight_deltas.append([x * error[1] * learning_rate for x in inputs])\n",
        "    return weight_deltas\n",
        "\n",
        "def update_weights(weights, weight_deltas):\n",
        "    for i in range(len(weights)):\n",
        "        for j in range(len(weights[i])):\n",
        "            weights[i][j] -= weight_deltas[i][j]\n",
        "    return weights\n",
        "progress = {}\n",
        "for epoch in range(num_epochs):\n",
        "    preds = network(inputs, weights)\n",
        "    errs = errors(preds, targets, progress)\n",
        "    deltas = weight_deltas(errs, inputs)\n",
        "    weights = update_weights(weights, deltas)\n",
        "\n"
      ],
      "metadata": {
        "id": "wRTrQ-95KH1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Initialize weights and biases\n",
        "random.seed(142)\n",
        "weights = [random.random() for x in range(9)]\n",
        "weights = [[x * 10 for x in weights[:3]], [x * 10 for x in weights[3:6]], [x * 10 for x in weights[6:]]]\n",
        "biases = [random.random() * 10 for _ in range(3)]\n",
        "\n",
        "# Generate batch of inputs and corresponding targets\n",
        "batch_size = 4\n",
        "inputs_batch = [[1.2, -2.6, 0.3], [0.5, 1.2, -1.3], [2.1, -1.9, 0.7], [0.8, -0.6, 0.2]]\n",
        "targets_batch = [[-5, 7, 25], [3, -2, 0], [10, 5, -1], [-7, 8, 3]]\n",
        "\n",
        "learning_rate = 0.01\n",
        "num_epochs = 100\n",
        "\n",
        "def forward(current_batch, current_layers_neurons_weights, neurons_biases):\n",
        "    \"\"\"\n",
        "    Compute the output of the current layer for each sample in the batch.\n",
        "\n",
        "    Args:\n",
        "        current_batch (list): A list of samples in the batch.\n",
        "        current_layers_neurons_weights (list): A list of weights for the neurons in the current layer.\n",
        "        neurons_biases (list): A list of biases for the neurons in the current layer.\n",
        "\n",
        "    Returns:\n",
        "        batch_outputs (list): A list where each entry corresponds to the output of the current layer\n",
        "                                for a sample in the batch. Each entry is a list of neuron outputs.\n",
        "                                If the layer has 3 neurons, each entry will have a length of 3.\n",
        "                                For example, if the current batch contains 1 sample and the layer has 3 neurons,\n",
        "                                the output will be:\n",
        "                                [[output of n1, output of n2, output of n3]]\n",
        "                                If the batch contains 2 samples, the output will be:\n",
        "                                [[output of n1, output of n2, output of n3],\n",
        "                                 [output of n1, output of n2, output of n3]]\n",
        "                                Each inner list represents the neuron outputs for a corresponding sample in the batch.\n",
        "    \"\"\"\n",
        "    batch_outputs = []\n",
        "\n",
        "    for each_sample in current_batch:\n",
        "        this_sample = each_sample\n",
        "        outputs_of_neurons = [0] * len(current_layers_neurons_weights)\n",
        "        for this_neuron, its_weights in enumerate(current_layers_neurons_weights):\n",
        "            bias_of_this_neuron = neurons_biases[this_neuron]\n",
        "            outputs_of_neurons[this_neuron] = bias_of_this_neuron  # Start with the bias\n",
        "            for feature_index, feature in enumerate(this_sample):\n",
        "                outputs_of_neurons[this_neuron] += its_weights[feature_index] * feature\n",
        "        batch_outputs.append(outputs_of_neurons)\n",
        "    return batch_outputs\n",
        "\n",
        "def batched_errors(batch_outputs, batch_targets):\n",
        "    batch_errors = []\n",
        "    for outputs, targets in zip(batch_outputs, batch_targets):\n",
        "        sample_errors = []\n",
        "        for output, target in zip(outputs, targets):\n",
        "            residual = (output - target)\n",
        "            squared_error = residual ** 2\n",
        "            sample_errors.append((squared_error, residual))\n",
        "        batch_errors.append(sample_errors)\n",
        "    return batch_errors\n",
        "\n",
        "def weight_deltas(batch_errors, inputs_batch):\n",
        "    batch_weight_deltas = []\n",
        "    bias_deltas = [0] * len(batch_errors[0])  # Initialize bias deltas to zero\n",
        "    for errors, inputs in zip(batch_errors, inputs_batch):\n",
        "        sample_weight_deltas = []\n",
        "        for neuron, error in enumerate(errors):\n",
        "            weight_delta = [x * error[1] * learning_rate for x in inputs]\n",
        "            sample_weight_deltas.append(weight_delta)\n",
        "            bias_deltas[neuron] += error[1] * learning_rate  # Accumulate bias delta\n",
        "        batch_weight_deltas.append(sample_weight_deltas)\n",
        "    return batch_weight_deltas, bias_deltas\n",
        "\n",
        "def update_weights(weights, biases, batch_weight_deltas, bias_deltas):\n",
        "    for weight_deltas in batch_weight_deltas:\n",
        "        for i in range(len(weights)):\n",
        "            for j in range(len(weights[i])):\n",
        "                weights[i][j] -= weight_deltas[i][j]\n",
        "    for i in range(len(biases)):\n",
        "        biases[i] -= bias_deltas[i] / len(batch_weight_deltas)  # Average the bias updates\n",
        "    return weights, biases\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    batch_preds = forward(inputs_batch, weights, biases)\n",
        "    batch_errors_ = batched_errors(batch_preds, targets_batch)\n",
        "    batch_weight_deltas, bias_deltas = weight_deltas(batch_errors_, inputs_batch)\n",
        "    weights, biases = update_weights(weights, biases, batch_weight_deltas, bias_deltas)\n",
        "\n",
        "print(\"Updated weights:\", weights)\n",
        "print(\"Updated biases:\", biases)\n"
      ],
      "metadata": {
        "id": "xT-yzmzgDVfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(forward)"
      ],
      "metadata": {
        "id": "ctvYz27lmAGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#inputs = [1.2, -2.6, 0.3]\n",
        "#weights = [-7.795804984329127, -15.128683088435594, -17.082497850798973]\n",
        "for i_batch, t_batch in zip(inputs_batch, targets_batch):\n",
        "    print(t_batch)\n",
        "    for updated_weights in weights:\n",
        "        result = [x* y for x, y in zip(i_batch, updated_weights)]\n",
        "        print(sum(result))\n",
        "\n",
        "help(forward)"
      ],
      "metadata": {
        "id": "8C077ky4-lgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight = 0.0\n",
        "bias = 0.0\n",
        "input = 0.5\n",
        "target = 0.8\n",
        "step_size = 0.001\n",
        "\n",
        "for iteration in range(641):\n",
        "    output = input * weight + bias\n",
        "    error = (output - target) ** 2\n",
        "    print(\"Error:\" + str(error) + \" Prediction:\" + str(output))\n",
        "\n",
        "    # Calculate errors for weight adjustment\n",
        "    up_output = input * (weight + step_size) + bias\n",
        "    up_error = (target - up_output) ** 2\n",
        "    down_output = input * (weight - step_size) + bias\n",
        "    down_error = (target - down_output) ** 2\n",
        "\n",
        "    if down_error < up_error:\n",
        "        weight = weight - step_size * input\n",
        "    elif down_error > up_error:\n",
        "        weight = weight + step_size * input\n",
        "\n",
        "    # Calculate errors for bias adjustment\n",
        "    up_output_bias = input * weight + (bias + step_size)\n",
        "    up_error_bias = (target - up_output_bias) ** 2\n",
        "    down_output_bias = input * weight + (bias - step_size)\n",
        "    down_error_bias = (target - down_output_bias) ** 2\n",
        "\n",
        "    if down_error_bias < up_error_bias:\n",
        "        bias = bias - step_size\n",
        "    elif down_error_bias > up_error_bias:\n",
        "        bias = bias + step_size\n",
        "\n"
      ],
      "metadata": {
        "id": "AE0a9-2lGbhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random.seed(42)  # For reproducibility\n",
        "\n",
        "# Initial weights, targets, and inputs\n",
        "weights = [0.5, 1.2, -0.1]\n",
        "# Each input set corresponds to a target value\n",
        "input_samples = [\n",
        "    [2.5, 0.5, 1.2],  # Inputs for target 90\n",
        "    [1.0, -0.5, 2.0], # Inputs for target 10\n",
        "    [-1.0, 2.5, 0.3]  # Inputs for target -30\n",
        "]\n",
        "targets = [90, 10, -30]\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 0.01\n",
        "num_epochs = 100\n",
        "\n",
        "for iteration in range(num_epochs):\n",
        "    total_error = 0\n",
        "\n",
        "    for inputs, target in zip(input_samples, targets):\n",
        "        pred = sum(input * weight for input, weight in zip(inputs, weights))\n",
        "        error_margin = pred - target\n",
        "        error = (pred - target) ** 2\n",
        "        total_error += error\n",
        "\n",
        "        weight_deltas = [input * error_margin * learning_rate for input in inputs]\n",
        "        weights = [weight - delta for weight, delta in zip(weights, weight_deltas)]\n",
        "\n",
        "        # Print intermediate values for testing\n",
        "        print(f\"Iteration {iteration}, Target {target}\")\n",
        "        print(f\"Prediction: {pred}, Error Margin: {error_margin}, Error: {error}\")\n",
        "        print(f\"Weight Deltas: {weight_deltas}\")\n",
        "        print(f\"Weights: {weights}\\n\")\n",
        "\n",
        "    print(f\"Total Error after iteration {iteration}: {total_error}\\n\")\n",
        "\n",
        "print(\"Final Weights:\", weights)\n",
        "\n",
        "# Calculate predicted values based on the final tuned weights and inputs\n",
        "final_predictions = []\n",
        "for inputs in input_samples:\n",
        "    pred = sum(input * weight for input, weight in zip(inputs, weights))\n",
        "    final_predictions.append(pred)\n",
        "\n",
        "print(\"Final Predictions based on tuned weights and inputs:\", final_predictions)\n"
      ],
      "metadata": {
        "id": "1ax_V9Dj-W5J"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgPU1JlwxB67TwBEpAJBTf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}