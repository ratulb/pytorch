{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP80a4ViuMuaYOoc9rNG+ue",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ratulb/pytorch/blob/main/regression_with_pytorch_builtins.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "w4a6XuczNUD3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from sklearn.datasets import load_diabetes\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes_sklearn_ds = load_diabetes(as_frame=True)\n",
        "features = torch.from_numpy(diabetes_sklearn_ds.data.to_numpy()).to(torch.float32)\n",
        "targets = torch.from_numpy(diabetes_sklearn_ds.target.to_numpy()).to(torch.float32)"
      ],
      "metadata": {
        "id": "sjuJBlq5mIQj"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = TensorDataset(features, targets)\n",
        "train_dl = DataLoader(train_ds, batch_size=5, shuffle=True)\n"
      ],
      "metadata": {
        "id": "bXBIHztAYSRv"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = F.mse_loss\n",
        "model = nn.Linear(features.shape[1], 1)\n",
        "print(model.weight)\n",
        "print(model.bias)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWn7UVI0ZZid",
        "outputId": "a677b331-1cc9-4f9b-e507-a01c636448d3"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0805,  0.0658, -0.0102, -0.1574,  0.1595,  0.0469, -0.3074, -0.0559,\n",
            "         -0.0858, -0.1349]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.1754], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility function to train the model\n",
        "def fit(num_epochs, model, loss_fn, optimizer, train_dl):\n",
        "\n",
        "    # Repeat for given number of epochs\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        # Train with batches of data\n",
        "        for xb,yb in train_dl:\n",
        "\n",
        "            # 1. Generate predictions\n",
        "            pred = model(xb)\n",
        "\n",
        "            # 2. Calculate loss\n",
        "            loss = loss_fn(pred, yb)\n",
        "\n",
        "            # 3. Compute gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # 4. Update parameters using gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            # 5. Reset the gradients to zero\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        # Print the progress\n",
        "        if (epoch+1) % 10 == 0:\n",
        "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
      ],
      "metadata": {
        "id": "bAm8TZ0TZZhX"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit(num_epochs=200, model=model, loss_fn=loss_fn, optimizer=optimizer, train_dl=train_dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxfdZMqbf7RY",
        "outputId": "9c084169-b09a-4326-c9d5-7de77ce7d547"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-68-db62d5b15330>:14: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  loss = loss_fn(pred, yb)\n",
            "<ipython-input-68-db62d5b15330>:14: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  loss = loss_fn(pred, yb)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/200], Loss: 7741.5239\n",
            "Epoch [20/200], Loss: 7856.1235\n",
            "Epoch [30/200], Loss: 20032.1621\n",
            "Epoch [40/200], Loss: 8681.7949\n",
            "Epoch [50/200], Loss: 52459.8828\n",
            "Epoch [60/200], Loss: 23898.6152\n",
            "Epoch [70/200], Loss: 28286.1582\n",
            "Epoch [80/200], Loss: 25529.1895\n",
            "Epoch [90/200], Loss: 41234.5469\n",
            "Epoch [100/200], Loss: 4020.1562\n",
            "Epoch [110/200], Loss: 4323.8682\n",
            "Epoch [120/200], Loss: 7130.0869\n",
            "Epoch [130/200], Loss: 25117.6621\n",
            "Epoch [140/200], Loss: 26548.2559\n",
            "Epoch [150/200], Loss: 21562.1094\n",
            "Epoch [160/200], Loss: 1442.2836\n",
            "Epoch [170/200], Loss: 32203.5762\n",
            "Epoch [180/200], Loss: 26554.9199\n",
            "Epoch [190/200], Loss: 23575.0391\n",
            "Epoch [200/200], Loss: 25160.0898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SnIF22I5lhpu"
      },
      "execution_count": 69,
      "outputs": []
    }
  ]
}